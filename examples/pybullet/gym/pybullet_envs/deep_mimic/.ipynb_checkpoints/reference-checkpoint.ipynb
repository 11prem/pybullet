{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inverse_kinect import *\n",
    "from common.h36m_dataset import Human36mDataset\n",
    "from common.camera import *\n",
    "\n",
    "import os,  inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(os.path.dirname(currentdir))\n",
    "os.sys.path.insert(0,parentdir)\n",
    "\n",
    "from pybullet_utils.bullet_client import BulletClient\n",
    "from pybullet_envs.deep_mimic.motion_capture_data import MotionCaptureData\n",
    "# import pybullet_data\n",
    "import pybullet\n",
    "import time\n",
    "import random\n",
    "\n",
    "from humanoid import Humanoid\n",
    "from humanoid import HumanoidPose\n",
    "\n",
    "import pybullet as p\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_info = {\n",
    "\t'joint_name':['root', 'right_hip', 'right_knee', 'right_ankle', 'left_hip', 'left_knee', 'left_ankle', 'chest', 'neck', 'nose', 'eye', 'left_shoulder', 'left_elbow', 'left_wrist', 'right_shoulder', 'right_elbow', 'right_wrist'],\n",
    "    'father':[0, 0, 1, 2, 0, 4, 5, 0, 7, 8, 9, 8, 11, 12, 8, 14, 15],\n",
    "    'side':['middle', 'right', 'right', 'right', 'left', 'left', 'left', 'middle', 'middle', 'middle', 'middle', 'left', 'left', 'left', 'right', 'right', 'right'] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_fb_h36m_dataset(dataset_path):\n",
    "    dataset = Human36mDataset(dataset_path)\n",
    "    print('Preparing Facebook H36M data...')\n",
    "    for subject in dataset.subjects():\n",
    "        for action in dataset[subject].keys():\n",
    "            anim = dataset[subject][action]\n",
    "            positions_3d = []\n",
    "            for cam in anim['cameras']:\n",
    "                pos_3d = world_to_camera(anim['positions'], R=cam['orientation'], t=cam['translation'])\n",
    "                pos_3d[:, 1:] -= pos_3d[:, :1] # Remove global offset, but keep trajectory in first position\n",
    "                positions_3d.append(pos_3d)\n",
    "            anim['positions_3d'] = positions_3d\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_fb_prediction_dataset(dataset_path):\n",
    "    dataset_file = open(dataset_path,\"rb\")\n",
    "    dataset = pickle.load(dataset_file)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_fb_prediction_json_dataset(dataset_path):\n",
    "    dataset_file = open(dataset_path,\"r\")\n",
    "    dataset = json.load(dataset_file)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose3D_from_fb_h36m(dataset, subject, action, shift):\n",
    "    pose_seq = dataset[subject][action]['positions_3d'][0].copy()\n",
    "    trajectory = pose_seq[:, :1]\n",
    "    pose_seq[:, 1:] += trajectory\n",
    "    # Invert camera transformation\n",
    "    cam = dataset.cameras()[subject][0]\n",
    "    pose_seq = camera_to_world(pose_seq, \n",
    "                                   R=cam['orientation'], \n",
    "                                   t=cam['translation'])\n",
    "    x = pose_seq[:,:,0:1]\n",
    "    y = pose_seq[:,:,1:2] * -1\n",
    "    z = pose_seq[:,:,2:3] \n",
    "    pose_seq = np.concatenate((x,z,y),axis=2)\n",
    "    # plus shift\n",
    "    pose_seq += np.array([[shift for i in range(pose_seq.shape[1])] for j in range(pose_seq.shape[0])])\n",
    "    return pose_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose3D_from_fb_prediction(dataset, subject, shift):\n",
    "    should_right = [1,2,3,14,15,16]\n",
    "    should_left = [4,5,6,11,12,13]\n",
    "    pose_seq = dataset[subject]\n",
    "    for i in range(pose_seq.shape[0]):\n",
    "        for j in range(pose_seq.shape[1]):\n",
    "            if i in should_right:\n",
    "                t = pose_seq[i][j]\n",
    "                change = should_left[should_right.index(i)]\n",
    "                pose_seq[i][j] = pose_seq[change][j]\n",
    "                pose_seq[change][j] = t\n",
    "    for i in range(pose_seq.shape[0]):\n",
    "        for j in range(pose_seq.shape[1]):\n",
    "            pose_seq[i][j][1] *= -1\n",
    "            pose_seq[i][j][2] *= -1\n",
    "\n",
    "    pose_seq += np.array([[shift for i in range(pose_seq.shape[1])] for j in range(pose_seq.shape[0])])\n",
    "    return pose_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose3D_from_fb_prediction_json(dataset, shift):\n",
    "    should_right = [1,2,3,14,15,16]\n",
    "    should_left = [4,5,6,11,12,13]\n",
    "    pose_seq = np.array(dataset['pose3d'])\n",
    "    for i in range(pose_seq.shape[0]):\n",
    "        for j in range(pose_seq.shape[1]):\n",
    "            if i in should_right:\n",
    "                t = pose_seq[i][j]\n",
    "                change = should_left[should_right.index(i)]\n",
    "                pose_seq[i][j] = pose_seq[change][j]\n",
    "                pose_seq[change][j] = t\n",
    "    for i in range(pose_seq.shape[0]):\n",
    "        for j in range(pose_seq.shape[1]):\n",
    "            pose_seq[i][j][1] *= -1\n",
    "            pose_seq[i][j][2] *= -1\n",
    "\n",
    "    pose_seq += np.array([[shift for i in range(pose_seq.shape[1])] for j in range(pose_seq.shape[0])])\n",
    "    return pose_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot_seq_to_deepmimic_json(rot_seq, loop, json_path):\n",
    "    to_json = {\"Loop\": loop, \"Frames\":[]}\n",
    "    rot_seq = np.around(rot_seq, decimals=6)\n",
    "    to_json[\"Frames\"] = rot_seq.tolist()\n",
    "    # In[14]:\n",
    "    to_file = json.dumps(to_json)\n",
    "    file = open(json_path,\"w\")\n",
    "    file.write(to_file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ground_truth(coord_seq, frame, duration, shift):\n",
    "    global joint_info\n",
    "    joint = coord_seq[frame]\n",
    "    shift = np.array(shift)\n",
    "    for i in range(1, 17):\n",
    "        # print(x[11], x[14])\n",
    "        joint_fa = joint_info['father'][i]\n",
    "        if joint_info['side'][i] == 'right':\n",
    "            p.addUserDebugLine(lineFromXYZ=joint[i]+shift,\n",
    "                               lineToXYZ=joint[joint_fa]+shift,\n",
    "                               lineColorRGB=(255,0,0),\n",
    "                               lineWidth=1,\n",
    "                               lifeTime=duration)\n",
    "        else:\n",
    "            p.addUserDebugLine(lineFromXYZ=joint[i]+shift,\n",
    "                               lineToXYZ=joint[joint_fa]+shift,\n",
    "                               lineColorRGB=(0,0,0),\n",
    "                               lineWidth=1,\n",
    "                               lifeTime=duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_h36m_dataset_path = 'data/data_3d_h36m.npz'\n",
    "dataset = init_fb_h36m_dataset(fb_h36m_dataset_path)\n",
    "ground_truth = pose3D_from_fb_h36m(dataset, \n",
    "                                   subject = 'S11', \n",
    "                                   action = 'Walking',\n",
    "                                   shift = [1.0,0.0,0.0])\n",
    "\n",
    "# # if load data from facebook output, set y-shift to 0.85\n",
    "# fb_prediction_dataset_path = 'data/tmp_3d_pose_data.pkl'\n",
    "# dataset = init_fb_prediction_dataset(fb_prediction_dataset_path)\n",
    "# ground_truth = pose3D_from_fb_prediction(  dataset, \n",
    "#                                            subject = 1, \n",
    "#                                            shift = [1.0,0.85,0.0])\n",
    "\n",
    "# # if load data from facebook output, set y-shift to 0.85\n",
    "# fb_prediction_json_dataset_path = 'data/pose3d-results-0.json'\n",
    "# dataset = init_fb_prediction_json_dataset(fb_prediction_json_dataset_path)\n",
    "# ground_truth = pose3D_from_fb_prediction_json(  dataset, \n",
    "#                                                 shift = [1.0,0.85,0.0])\n",
    "\n",
    "coord_seq = ground_truth\n",
    "rot_seq =  coord_seq_to_rot_seq(coord_seq = coord_seq, \n",
    "                                frame_duration = 1/24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t is threshold\n",
    "def rotation_sequence_clean(coord_seq, rot_seq, threshold):\n",
    "    clean_coord_seq = []\n",
    "    clean_rot_seq = []\n",
    "    for i in range(1, len(rot_seq)):\n",
    "        now = np.array(rot_seq[i])        \n",
    "        last = np.array(rot_seq[i-1])\n",
    "        dist = np.linalg.norm(now-last)\n",
    "#         test_mul = np.dot(now, last) / now.shape[0]\n",
    "        print(i, dist)\n",
    "        if dist <= threshold:\n",
    "            clean_rot_seq.append(rot_seq[i])\n",
    "            clean_coord_seq.append(coord_seq[i])\n",
    "    return [clean_coord_seq, clean_rot_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_seq, rot_seq = rotation_sequence_clean(coord_seq, rot_seq, threshold = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_seq_to_deepmimic_json(  rot_seq = rot_seq, \n",
    "                            loop = 'wrap',\n",
    "                            json_path = 'data/test_dance.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = BulletClient(connection_mode=pybullet.GUI)\n",
    "# bc.setAdditionalSearchPath(os.getcwd())\n",
    "bc.configureDebugVisualizer(bc.COV_ENABLE_Y_AXIS_UP,1)\n",
    "bc.setGravity(0,-9.8,0)\n",
    "motion=MotionCaptureData()\n",
    "\n",
    "# motionPath = pybullet_data.getDataPath()+\"/motions/humanoid3d_backflip.txt\"#humanoid3d_spinkick.txt\"#/motions/humanoid3d_backflip.txt\"\n",
    "motionPath = 'data/test_dance.json'\n",
    "motion.Load(motionPath)\n",
    "print(\"numFrames = \", motion.NumFrames())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simTimeId= bc.addUserDebugParameter(\"simTime\",0,motion.NumFrames()-1.1,0)\n",
    "\n",
    "y2zOrn = bc.getQuaternionFromEuler([-1.57,0,0])\n",
    "bc.loadURDF(\"data/plane.urdf\",[0,-0.04,0], y2zOrn)\n",
    "\n",
    "# humanoid = Humanoid(bc, motion, [0,0,0])#4000,0,5000])\n",
    "humanoid = Humanoid(bc, motion, [0,0,0]) #这是初始位置的坐标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p.getBasePositionAndOrientation(humanoid._humanoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simTime = 0\n",
    "keyFrameDuration = motion.KeyFrameDuraction()\n",
    "print(\"keyFrameDuration=\",keyFrameDuration)\n",
    "for utNum in range(motion.NumFrames()):\n",
    "    bc.stepSimulation()\n",
    "    # humanoid.ApplyPose(pose, True, True, humanoid._humanoid,bc)\n",
    "    humanoid.RenderReference(utNum * keyFrameDuration)\n",
    "    draw_ground_truth(coord_seq = coord_seq, \n",
    "                      frame = utNum, \n",
    "                      duration = keyFrameDuration,\n",
    "                      shift = [-1.0, 0.0, 1.0])\n",
    "    time.sleep(0.001)\n",
    "#     print(utNum, motion._motion_data['Frames'][utNum][4:8])\n",
    "stage = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reset(humanoid):\n",
    "\tglobal simTime\n",
    "\thumanoid.Reset()\n",
    "\tsimTime = 0 #random.randint(0,motion.NumFrames()-2)\n",
    "\thumanoid.SetSimTime(simTime)\n",
    "\tpose = humanoid.InitializePoseFromMotionData()\n",
    "\thumanoid.ApplyPose(pose, True, True, humanoid._humanoid,bc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reset(humanoid)\n",
    "p.disconnect()\n",
    "#bc.stepSimulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
